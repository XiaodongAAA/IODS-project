library(MASS)
library(corrplot)
library(tidyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
bins <- quantile(boston_scaled$crim)
boston_scaled=as.data.frame(boston_scaled)
bins <- quantile(boston_scaled$crim)
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
library(dplyr)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
train
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
train
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
lad.pred=predict(lad.fit,newdata=test)
lda.pred=predict(lad.fit,newdata=test)
lda.pred=predict(lda.fit,newdata=test)
table(correct=correct_classes,predicted=lad.pred$class)
table(correct=correct_classes,predicted=lda.pred$class)
table(correct=correct_classes,predicted=lda.pred$class) %>% prop.table %>% addmargins
table(correct=correct_classes,predicted=lda.pred$class) %>% addmargins
correct=c(16,23,13,26)
correct=c(correct,sum(correct))
correct
sumdata=c(27,30,18,27)
sumdata=c(sumdata,sum(sumdata))
t=data.frame(correct=correct,sum=sumdata)
t
index=c('low','med_low','med_high','high','sum')
t=data.frame(correct=index,correct_pred=correct,sum=sumdata)
t
t=data.frame(correct=index,predict(=correct,sum=sumdata)
t=data.frame(correct=index,predict=correct,sum=sumdata)
t
t$perc=t$predict/t$sum
t
correct=c(16,23,13,26)
correct=c(correct,sum(correct))
sumdata=c(27,30,18,27)
sumdata=c(sumdata,sum(sumdata))
index=c('low','med_low','med_high','high','sum')
t=data.frame(correct=index,predict=correct,sum=sumdata)
t$percentage=t$predict/t$sum
t
data('Boston')
boston_scaled=scale(Boston)
dist_eu=dist(boston_scaled,method='euclidean')
summary(dist_eu)
dist_man=dist(boston_scaled,method='manhattan')
summary(dist_man)
summary(boston_scaled)
dist_eu
km=kmeans(boston_scaled,centers = 3)
pairs(boston_scaled,col=km$cluster)
km=kmeans(boston_scaled,centers = 3)
pairs(boston_scaled[6:10],col=km$cluster)
pairs(boston_scaled,col=km$cluster)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,goem='line')
library(ggplot2)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,goem='line')
qplot(x=1:k_max,y=twcss,geom=line')
qplot(x=1:k_max,y=twcss,geom='line')
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,geom='line')
set.seed(123)
set.seed(123)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,geom='line')
km=kmeans(boston_scaled,centers=2)
pairs(boston_scaled,col=km$cluster)
pairs(boston_scaled,col=km$cluster)
pairs(boston_scaled[1:5],col=km$cluster)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
library(ggplot2)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
lda.pred=predict(lda.fit,newdata=test)
table(correct=correct_classes,predicted=lda.pred$class) %>% addmargins
correct=c(16,23,13,26)
correct=c(correct,sum(correct))
sumdata=c(27,30,18,27)
sumdata=c(sumdata,sum(sumdata))
index=c('low','med_low','med_high','high','sum')
t=data.frame(correct=index,predict=correct,sum=sumdata)
t$percentage=t$predict/t$sum
t
data('Boston')
boston_scaled=scale(Boston)
dist_eu=dist(boston_scaled,method='euclidean')
summary(dist_eu)
dist_man=dist(boston_scaled,method='manhattan')
summary(dist_man)
km=kmeans(boston_scaled,centers = 3)
pairs(boston_scaled,col=km$cluster)
set.seed(123)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,geom='line')
km=kmeans(boston_scaled,centers=2)
pairs(boston_scaled,col=km$cluster)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
library(ggplot2)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
lda.pred=predict(lda.fit,newdata=test)
table(correct=correct_classes,predicted=lda.pred$class) %>% addmargins
correct=c(16,23,13,26)
correct=c(correct,sum(correct))
sumdata=c(27,30,18,27)
sumdata=c(sumdata,sum(sumdata))
index=c('low','med_low','med_high','high','sum')
t=data.frame(correct=index,predict=correct,sum=sumdata)
t$percentage=t$predict/t$sum
t
data('Boston')
boston_scaled=scale(Boston)
dist_eu=dist(boston_scaled,method='euclidean')
summary(dist_eu)
dist_man=dist(boston_scaled,method='manhattan')
summary(dist_man)
km=kmeans(boston_scaled,centers = 3)
pairs(boston_scaled,col=km$cluster)
set.seed(123)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,geom='line')
km=kmeans(boston_scaled,centers=2)
pairs(boston_scaled,col=km$cluster)
library(MASS)
library(corrplot)
library(tidyr)
library(dplyr)
library(ggplot2)
data("Boston")
str(Boston)
dim(Boston)
cor_matrix<-cor(Boston) %>% round(2)
corrplot(cor_matrix, method="circle",type='upper',cl.pos='b',tl.pos='d',tl.cex=0.6)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled=as.data.frame(boston_scaled)
bins=quantile(boston_scaled$crim)
crime=cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c('low','med_low','med_high','high'))
table(crime)
boston_scaled=dplyr::select(boston_scaled, -crim)
boston_scaled=data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train <- boston_scaled[ind,]
test <- boston_scaled[-ind,]
correct_classes <- test$crime
test <- dplyr::select(test, -crime)
lda.fit <- lda(crime~., data = train)
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2,col=classes,pch=classes)
lda.arrows(lda.fit, myscale = 3)
lda.pred=predict(lda.fit,newdata=test)
table(correct=correct_classes,predicted=lda.pred$class) %>% addmargins
correct=c(16,23,13,26)
correct=c(correct,sum(correct))
sumdata=c(27,30,18,27)
sumdata=c(sumdata,sum(sumdata))
index=c('low','med_low','med_high','high','sum')
t=data.frame(correct=index,predict=correct,sum=sumdata)
t$percentage=t$predict/t$sum
t
data('Boston')
boston_scaled=scale(Boston)
dist_eu=dist(boston_scaled,method='euclidean')
summary(dist_eu)
dist_man=dist(boston_scaled,method='manhattan')
summary(dist_man)
km=kmeans(boston_scaled,centers = 3)
pairs(boston_scaled,col=km$cluster)
set.seed(123)
k_max=10
twcss=sapply(1:k_max,function(k){kmeans(boston_scaled,k)$tot.withinss})
qplot(x=1:k_max,y=twcss,geom='line')
km=kmeans(boston_scaled,centers=2)
pairs(boston_scaled,col=km$cluster)
# Read the human data
#human=read.table('
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
hd
head(hd)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
#head(gii)
head(gii)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
head(hd)
head(gii)
colnames(hd)
colnames_hd=colnames(hd)
colnames_hd[3]=HDI
colnames_hd[3]='HDI'
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
head(hd)
colnames(gii)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
names(gii)
# Calculate the ratio of female and male populations with secondary education and labour force participation in each country
gii=mutate(gii,Edu2.FM=Edu2.F/Edu2.M,Labo.FM=Labo.F/Labo.M)
gii
dim(hd)
dim(gii)
# Join the two datasets
human=inner_join(hd,gii,by='Country')
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
tail(human)
summary(human)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
library(dplyr)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
tail(human)
dim(human)
head(human)
library(stringr)
# Mutate the GNI data in 'human' dataset
str(human$GNI)
str_replace(human$GNI,pattern=',',replace='') %>% as.numeric
human$GNI=str_replace(human$GNI,pattern=',',replace='') %>% as.numeric
str(human)
# Dealing with not available (NA) values
keep=c("Country", "Edu2.FM", "Labo.FM", "Life.Exp", "Edu.Exp", "GNI", "Mat.Mor", "Ado.Birth", "Parli.F")
human=select(human,one_of(keep))
human=filter(human,complete.cases(human))
tail(human,10)
human$Country
# Remove observations with related to regions instead of countries
last=nrow(human)-7
human_=human[1:last,]
head(human_)
# Define the row names of the data by the country names
rownames(human_)=human$Country
# Define the row names of the data by the country names
rownames(human_)=human_$Country
human_=human_(-1)
human_=human_[-1]
head(human_)
dim(human_)
human=human_[-1]
# Save data
setwd('/home/xiaodong/IODS_course/IODS-project/data')
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
human
source('~/IODS_course/IODS-project/data/creat_human.R', echo=TRUE)
human = read.table('/home/xiaodong/IODS_course/IODS-project/data/human.txt',sep='\t',header = TRUE)
head(human)
